{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\spashikanti\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (3.4)\n",
      "Requirement already satisfied: six in c:\\users\\spashikanti\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from nltk) (1.10.0)\n",
      "Requirement already satisfied: singledispatch in c:\\users\\spashikanti\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from nltk) (3.4.0.3)\n"
     ]
    }
   ],
   "source": [
    "# Install nltk package\n",
    "import sys \n",
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log.py, word.py, porter2.py\n",
    "* No changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the script global logger\n",
    "def ext_print (name):\n",
    "\ttnow = datetime.now()\n",
    "\tname = '['+str(tnow)+'] ' +name\n",
    "\treturn name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usage:\n",
    "#from utility.log import strd_logger\n",
    "#from cgi import log\n",
    "#log = strd_logger ('XXXX')\n",
    "#log.error ('XXX')\n",
    "#log.info ('XXX')\n",
    "\n",
    "# define the script global logger\n",
    "def strd_logger (name):\n",
    "\tlog = logging.getLogger (name)\n",
    "\tlog.setLevel (logging.INFO)\n",
    "\t#formatter = logging.Formatter('[%(asctime)s %(levelname)s] %(message)s', \"%Y-%m-%d %H:%M:%S\")\n",
    "\tformatter = logging.Formatter('[%(asctime)s.%(msecs)d %(levelname)s] %(message)s','%Y-%m-%d,%H:%M:%S')\n",
    "\thandler = logging.StreamHandler()\n",
    "\thandler.setFormatter(formatter)\n",
    "\tlog.addHandler(handler)\n",
    "\treturn log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file.py\n",
    "* cpickle is to be replaced with pickle in file.py\n",
    "* csv.field_size_limit(sys.maxint) line is to be replaced with\n",
    "    - maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "* from log import strd_logger is to be replaced with\n",
    "    - from W_utility.log import strd_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re, math, csv, shutil, os, sys, glob, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from W_utility.log import strd_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import W_utility.file as ufile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentence.py\n",
    "* import word as NLP_word\n",
    "    - import NLP.word as NLP_word\n",
    "* import porter2 \n",
    "    - import NLP.porter2 as porter2\n",
    "* Replace xrange with range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NLP.porter2 as porter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NLP.word as NLP_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NLP import sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentence_keywords.py\n",
    "* import sentence as NLP_sent\n",
    "    - import NLP.sentence as NLP_sent\n",
    "* import word as NLP_word\n",
    "    - import NLP.word as NLP_word\n",
    "* Add Code\n",
    "    - import nltk\n",
    "    - nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SPashikanti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from NLP import sentence_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### After making changes to the codes - To import all the functions \n",
    "from W_utility.log import * \n",
    "from W_utility.file import * \n",
    "\n",
    "from NLP.porter2 import *\n",
    "from NLP.word import *\n",
    "from NLP.sentence import *\n",
    "from NLP.sentence import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valx_core.py\n",
    "* init_features () needs to be excuted for global variable decleration of the mentions variables\n",
    "* In 'preprocessing' function: text = text.decode('ascii', 'ignore') is to replaced with\n",
    "    - text = text.encode().decode('ascii', 'ignore')\n",
    "* In 'extract_candidates_name' function: add any of the below statements\n",
    "    - name_list = \"\"\n",
    "    - name_list = \"hb1ac | heart rate\" #Implies only sentences with these 2 tests are extracted\n",
    "* In 'formalize_expressions' function: http://www.pyregex.com/\n",
    "    - csvfile = open('data\\\\rules.csv', 'rb') replaced with csvfile = open('data\\\\rules.csv', 'r') #r instead or rb\n",
    "    - global selects replaced with selects = value in numeric_features.csv\n",
    "    - global between replaced with between = \"range of X to X|range X to X|range X - X|between X to X|between X and X|between Xand X|between X - X|between X & X|from X to X|within X to X|start X and X|X through X|of X and X|>= X and X|> X and X|of X to X|>= X to <= X|>= X to X|> X to X|X - <= X|X to X|X - X\"\n",
    "* Execute below commands after executing 'identify_variable' function\n",
    "    - fea_dict_dk = ufile.read_csv_as_dict ('data\\\\variable_features_dk.csv', 0, 1, True)\n",
    "    - fea_dict_umls = ufile.read_csv_as_dict ('data\\\\variable_features_umls.csv', 0, 1, True)\n",
    "\n",
    "    - Eg: ClincalNote_identify_variable = identify_variable(ClincalNote_formalize_expressions, fea_dict_dk, fea_dict_umls)\n",
    "        - ClincalNote_identify_variable      \n",
    "* In 'normalization' function \n",
    "    - if exp[3]<>'' and exp[3] <> 'kg/m2' - this line modification \"<>\" is to be replaced with \"!=\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import Valx_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------Define representative logics and their candidate representations \n",
    "\n",
    "greater, greater_equal, greater_equal2, lower, lower_equal, lower_equal2, equal, between, selects, connect, features, temporal, temporal_con, error1, error2, symbols, numbers, unit_special, unit_ori, unit_ori_s, unit_exp, negation = \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
    "\n",
    "def init_features ():\n",
    "    feature_set = ufile.read_csv_as_dict ('data\\\\numeric_features.csv', 0, 1, True)\n",
    "    global greater, greater_equal, greater_equal2, lower, lower_equal, lower_equal2, equal, between, selects, connect, features, temporal, temporal_con, error1, error2, symbols, numbers, unit_special, unit_ori, unit_ori_s, unit_exp, negation\n",
    "    greater, greater_equal, greater_equal2, lower, lower_equal, lower_equal2, equal, between, selects, connect, features, temporal, temporal_con, error1, error2, symbols, numbers, unit_special, unit_ori, unit_ori_s, unit_exp, negation = \\\n",
    "    feature_set[\"greater\"], feature_set[\"greater_equal\"], feature_set[\"greater_equal2\"], feature_set[\"lower\"], feature_set[\"lower_equal\"], feature_set[\"lower_equal2\"], feature_set[\"equal\"], feature_set[\"between\"], feature_set[\"selects\"], feature_set[\"connect\"], feature_set[\"features\"], feature_set[\"temporal\"], feature_set[\"temporal_con\"], feature_set[\"error1\"], feature_set[\"error2\"], feature_set[\"symbols\"], feature_set[\"numbers\"], feature_set[\"unit_special\"], feature_set[\"unit_ori\"], feature_set[\"unit_ori_s\"], feature_set[\"unit_exp\"], feature_set[\"negation\"]\n",
    "    temporal = temporal + '|' + temporal.replace('|', 's|') + 's'\n",
    "    unit = (unit_ori + \"|\" + unit_ori_s.replace(\"|\", \"s|\") + \"s|\" + unit_ori_s + \"|\" + temporal)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_features () #Needs to be executed for the global variables decleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing (text):\n",
    "    # handle special characters\n",
    "    text = text.encode().decode('ascii', 'ignore') # text = text.decode('ascii', 'ignore')\n",
    "\n",
    "    text = text.strip().replace('\\n\\n', '#')\n",
    "    text = text.replace ('\\n', '')\n",
    "    text = text.replace(u'＝','=').replace(u'＞', '>').replace(u'＜','<').replace(u'≤','<=').replace (u'≥','>=').replace(u'≦','<=').replace(u'≧','>=').replace(u'mm³','mm^3').replace(u'µl','ul').replace(u'µL','ul').replace(u'·','').replace(u'‐','-').replace(u'—','-')\n",
    "\n",
    "    text = text.replace('((', '(').replace('))', ')')\n",
    "    text = re.sub('(\\d+)( |)(~|/|&|\\|)( |)(\\d+)',r'\\1 - \\5',text) # e.g., '10~20' to '10 ~ 20'\n",
    "    text = re.sub(r\"(\\d+),(\\d{3})\", r'\\1\\2', text) # 10,123 to 10123\n",
    "    text = re.sub(r\"(\\d+),(\\d{1,2})\", r'\\1.\\2', text) # 10,1 to 10.1\n",
    "    text = re.sub(r\"between (\\d+), (\\d{1,2}) (and|or) \", r'between \\1.\\2 \\3 ', text) # 'between 7, 5 and ' to 'between 7.5 and '\n",
    "    while '  ' in text:\n",
    "        text = text.replace('  ',' ')\n",
    "    # avoid connected values separated by splitting, e.g., \", but below 10%\"\n",
    "    text = re.sub(\", (\"+connect+\") \", r' \\1 ', text) # \n",
    "\n",
    "    return text.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_inclusion_exclusion(otext):\n",
    "    in_fea = 'inclusion criteria:|key inclusion criteria|inclusion criteria [^:#;\\.]+:|inclusion:|(?<!(\\w| ))inclusion criteria\\W\\W|inclusion for'\n",
    "    ex_fea = 'exclusion criteria:|key exclusion criteria|exclusion criteria [^:#;\\.]+:|exclusion:|(?<!(\\w| ))exclusion criteria\\W\\W|exclusion for'\n",
    "   \n",
    "    in_text, ex_text = '', ''\n",
    "    in_bool = True\n",
    "\n",
    "    text = otext.lower()\n",
    "    while text != '':\n",
    "        if in_bool:\n",
    "            n_pos = re.search('('+ex_fea+')',text)\n",
    "            if n_pos is not None:\n",
    "                in_text += text[0:n_pos.start()]\n",
    "                text = text[n_pos.start():]\n",
    "            else:\n",
    "                in_text += text[0:]\n",
    "                text = ''\n",
    "        else:\n",
    "            n_pos = re.search('('+in_fea+')',text)\n",
    "            if n_pos is not None:\n",
    "                ex_text += text[0:n_pos.start()]\n",
    "                text = text[n_pos.start():]\n",
    "            else:\n",
    "                ex_text += text[0:]\n",
    "                text = ''\n",
    "        in_bool = False if in_bool else True\n",
    "    \n",
    "    sections_text =[]\n",
    "    if in_text !='': sections_text.append([\"Inclusion\", in_text])\n",
    "    if ex_text !='': sections_text.append([\"Exclusion\", ex_text])    \n",
    "    return sections_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====find expression candidates according to pre-defined feature list\n",
    "def extract_candidates_numeric (text):\n",
    "    # process text\n",
    "    sections_text = split_text_inclusion_exclusion(text)\n",
    "    \n",
    "    sections_num = []\n",
    "    candidates_num = []\n",
    "      \n",
    "    for section_text in sections_text:        \n",
    "        sentences = sentence.sentence_splitting_symbols(section_text[1], \"[#!?.;]\\s\", 1)\n",
    "        for sent in sentences:\n",
    "            sent = sent.strip().strip('- ')\n",
    "            if sent == '':\n",
    "                continue\n",
    "                \n",
    "            digit = re.search(\"(?<!(\\w))\\d+\", sent)\n",
    "            if digit:\n",
    "                sections_num.append(section_text[0])\n",
    "                candidates_num.append(sent)\n",
    "\n",
    "    return (sections_num, candidates_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = \"\"\n",
    "name_list = \"heart rate | temperature | blood pressure\"\n",
    "def extract_candidates_name (sections_num, candidates_num, name_list):\n",
    "    sections = []\n",
    "    candidates = []\n",
    "    names = name_list.split('|')\n",
    "    for i in xrange(len(candidates_num)):            \n",
    "        for name in names:\n",
    "           if name in candidates_num[i]:\n",
    "                sections.append(sections_num[i])\n",
    "                candidates.append(candidates_num[i])\n",
    "                break\n",
    "\n",
    "    return (sections, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.pyregex.com/\n",
    "\n",
    "#====identify expressions and formalize them into labels \"<VML(tag) L(logic, e.g., greater_equal)=X U(unit)=X>value</VML>\"\n",
    "def formalize_expressions (candidate):\n",
    "    text = candidate\n",
    "    csvfile = open('data\\\\rules.csv', 'r')\n",
    "    reader = csv.reader(csvfile)\n",
    "    now_pattern = \"preprocessing\"\n",
    "\n",
    "    for i,pattern in enumerate(reader):\n",
    "        source_pattern = pattern[0]\n",
    "        target_pattern = pattern[1]\n",
    "        pattern_function = pattern[2]\n",
    "\n",
    "        if(pattern_function == \"process_numerical_values\" and pattern_function != now_pattern):\n",
    "            matchs = re.findall('<Unit>([^<>]+)</Unit>', text)\n",
    "            for match in matchs: text = text.replace(match, match.replace(' / ', '/').replace(' - ','-'))\n",
    "\n",
    "        if(pattern_function == \"process_special_logics\" and pattern_function != now_pattern):\n",
    "            # process 'select' expression, use the first one\n",
    "            selects = \"X \\( X \\)|X \\( equal to X \\)|X \\( = X\\)\"\n",
    "            aselect = selects.split('|')\n",
    "            for selec in aselect:\n",
    "                selec = selec.replace('X', '<VML Unit([^<>]+)>([^<>]+)</VML>')\n",
    "                text = re.sub(selec, r'<VML Unit\\1>\\2</VML>', text) #\n",
    "\n",
    "            #  process 'between' expressions\n",
    "            between = \"range of X to X|range X to X|range X - X|between X to X|between X and X|between Xand X|between X - X|between X & X|from X to X|within X to X|start X and X|X through X|of X and X|>= X and X|> X and X|of X to X|>= X to <= X|>= X to X|> X to X|X - <= X|X to X|X - X\"\n",
    "            betweens = between.split('|')\n",
    "            for betw in betweens:\n",
    "                betw = betw.replace('X', '<VML Unit([^<>]+)>([^<>]+)</VML>')\n",
    "                text = re.sub(betw, r'<VML Logic=greater_equal Unit\\1>\\2</VML> - <VML Logic=lower_equal Unit\\3>\\4</VML>', text) #\n",
    "        text = re.sub(source_pattern, target_pattern, text)\n",
    "        now_pattern = pattern_function\n",
    "\n",
    "    csvfile.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_mentions_front = 'total|absolute|mean|average|abnormal|gross'\n",
    "add_mentions_back = 'test results|test result|test scores|test score|tests|test|scores|score|results|result|values|value|levels|level|ratios|ratio|counts|count|volume'\n",
    "def identify_variable (exp_text, fea_dict_dk, fea_dict_umls):\n",
    "    # find candidate string\n",
    "    if exp_text.find('<VML') == -1:\n",
    "        return (exp_text, [])\n",
    "    can_texts = re.findall('(\\A|VML>)(.+?)(<VML|\\Z)',exp_text) \n",
    "    \n",
    "    # generate n-grams\n",
    "    first_ngram, key_ngrams = '', [] # first ngram; key ngrams are the ngrams except the ngrams match with domain knowledge and umls\n",
    "    match = False\n",
    "    for cantext in can_texts:\n",
    "        if '<VL Label' in cantext[1]: \n",
    "            ngrams = re.findall('<VL Label=([^<>]+) Source', cantext[1])\n",
    "            for ngram in ngrams:# judge if they are potential variables\n",
    "                if ngram in fea_dict_dk:\n",
    "                    exp_text = re.sub(r'<VL Label='+ngram+' Source=', r\"<VL Label=%s Source=\" % fea_dict_dk[ngram], exp_text)\n",
    "                elif ngram in fea_dict_umls:\n",
    "                    exp_text = re.sub(r'<VL Label='+ngram+' Source=', r\"<VL Label=%s Source=\" % fea_dict_umls[ngram], exp_text)\n",
    "            match = True\n",
    "        else:\n",
    "            ngrams = sentence_keywords.keywords_ngrams_reverse(cantext[1].replace(' - ', '-').strip())\n",
    "            if len(ngrams) > 0:\n",
    "                longest_str = max(ngrams, key=len)\n",
    "                key_ngrams.append(longest_str)\n",
    "                if first_ngram == '': first_ngram = longest_str\n",
    "            for ngram in ngrams:# judge if they are potential variables\n",
    "                if ngram in fea_dict_dk:\n",
    "                    if ngram in key_ngrams: key_ngrams.remove(ngram)\n",
    "                    exp_text = re.sub(r'(?<!(\\w|<|>))'+ngram+'(?!(\\w|<|>))', r\"<VL Label=%s Source=DK>%s</VL>\" % (fea_dict_dk[ngram], ngram), exp_text, 1)\n",
    "                    match = True\n",
    "                    break\n",
    "                elif ngram in fea_dict_umls:\n",
    "                    if ngram in key_ngrams: key_ngrams.remove(ngram)\n",
    "                    exp_text = re.sub(r'(?<!(\\w|<|>))'+ngram+'(?!(\\w|<|>))', r\"<VL Label=%s Source=UMLS>%s</VL>\" % (fea_dict_umls[ngram], ngram), exp_text, 1)\n",
    "                    match = True\n",
    "                    break\n",
    "\n",
    "    exp_text = re.sub(r'<VL ([^>]+)<VL Label=[^<>]+>([^<>]+)</VL>',r'<VL \\1\\2', exp_text)\n",
    "    exp_text = re.sub(r'(?<!(\\w|<|>|=))('+add_mentions_front+') <VL Label=([^<>]+) Source=([^<>]+)>([^<>]+)</VL>', r\"<VL Label=\\2 \\3 Source=\\4>\\2 \\5</VL>\", exp_text)\n",
    "    exp_text = re.sub(r'</VL>'+' ('+add_mentions_back+r')(?!(\\w|<|>))', r\" \\1</VL>\", exp_text)\n",
    "\n",
    "    if len(can_texts)>0 and not match and first_ngram.strip() != '': #guess variable\n",
    "        exp_text = exp_text.replace(first_ngram, \"<VL Label=%s Source=ngram>%s</VL>\" % (first_ngram, first_ngram), 1)\n",
    "#     marks =re.findall(r'<VL Label=([^<>]+)>[^<>]+</VL>', exp_text)\n",
    "\n",
    "    return (exp_text, key_ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def associate_variable_values(exp_text):\n",
    "    # reorder exp_text to arrange variable values in order\n",
    "    can_str = exp_text\n",
    "    can_str = re.sub(r'<VL ([^<>]+)>([^<>]+)</VL> <VML ([^<>]+)>([^<>]+)</VML> <VL ([^<>]+)>([^<>]+)</VL>', r'<VL \\1>\\2</VL> <VML \\3>\\4</VML>; <VL \\5>\\6</VL>', can_str) \n",
    "    can_str = re.sub(r'<VML ([^<>]+)>([^<>]+)</VML> (-|to|and) <VML ([^<>]+)>([^<>]+)</VML>( of| for) <VL ([^<>]+)>([^<>]+)</VL>', r'<VL \\7>\\8</VL> <VML \\1>\\2</VML> \\3 <VML \\4>\\5</VML>', can_str) \n",
    "    can_str = re.sub(r'<VML ([^<>]+)>([^<>]+)</VML>( of| for) <VL ([^<>]+)>([^<>]+)</VL>', r'<VL \\4>\\5</VL> <VML \\1>\\2</VML>', can_str) \n",
    "    \n",
    "    # find association    \n",
    "    variables, vars_values = [], []\n",
    "    start = 0\n",
    "    while can_str.find('<VL') >-1 and can_str.find('<VML') >-1:\n",
    "        con1 = can_str.find('<VL')\n",
    "        start = 0 if start == 0 else con1\n",
    "        end = can_str.find('<VL' , con1+1)\n",
    "        if end > -1:\n",
    "            text = can_str[start:end] # pos could be -1 so curr_str always ends with a space\n",
    "            can_str = can_str[end:]\n",
    "        else:\n",
    "            text = can_str[start:] # pos could be -1 so curr_str always ends with a space\n",
    "            can_str = ''\n",
    "        # get all values in the range\n",
    "        var =re.findall(r'<VL Label=([^<>]+) Source=([^<>]+)>([^<>]+)</VL>', text) # get last VL label as variable\n",
    "        values =re.findall(r'<VML Logic=([^<>]+) Unit=([^<>]*)>([^<>]+)</VML>', text)\n",
    "        if len(var) > 0 and len(values) > 0:\n",
    "            variables.append(var[0][0])\n",
    "            var_values = []\n",
    "            for value in values: \n",
    "                logic_for_view = value[0].replace('greater', '>').replace('lower', '<').replace('equal', '=').replace('_', '')\n",
    "                var_values.append([var[0][0], logic_for_view, value[2], value[1].strip()])\n",
    "            vars_values.append(var_values)\n",
    "\n",
    "    return (variables, vars_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_validation (var_values, allow_units, error_units):\n",
    "\n",
    "    # unit based validation\n",
    "    curr_exps = []\n",
    "    allow_units = (str(allow_units).replace(\"TEMPORAL\", temporal)).split('|')\n",
    "    error_units = (str(error_units).replace(\"TEMPORAL\", temporal)).split('|')\n",
    "    for exp in var_values:\n",
    "        if exp[3].startswith('x ') or exp[3].startswith('times'):\n",
    "            condition = True\n",
    "        elif error_units == ['ALL_OTHER']:\n",
    "            condition = (exp[3]=='' or exp[3] in allow_units)\n",
    "        else:\n",
    "            condition = (exp[3]=='' or exp[3] in allow_units or exp[3] not in error_units)\n",
    "        if condition:\n",
    "            curr_exps.append(exp)\n",
    "\n",
    "    return curr_exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================normalize the unit and their corresponding values\n",
    "def normalization (nor_unit, exps):\n",
    "#     for i in xrange(len(exps)):\n",
    "    exp_temp = []\n",
    "    for exp in exps:\n",
    "        if ' x ' in exp[2]: \n",
    "            temp = exp[2].strip().split(' x ')\n",
    "            exp[2] = 1\n",
    "            for tem in temp:\n",
    "                exp[2] = exp[2] * float(tem)\n",
    "        elif '^' in exp[2]:\n",
    "            temp = exp[2].split('^')\n",
    "            x,y = float(temp[0].strip()),float(temp[1].strip())\n",
    "            exp[2] = math.pow(x, y)\n",
    "        else:\n",
    "            exp[2] = float(exp[2])\n",
    "        # start define unit conversion\n",
    "        if nor_unit == '%':\n",
    "            if exp[3] == '' and exp[2] < 1:\n",
    "                exp[2], exp[3] = exp[2]*100.0, nor_unit\n",
    "            elif exp[3].startswith('percent'):\n",
    "                exp[3] = nor_unit\n",
    "            elif exp[3].startswith('mmol/mol'):\n",
    "                exp[2], exp[3] = exp[2]/10.0, nor_unit\n",
    "            elif exp[3] =='':\n",
    "                exp[3] = nor_unit\n",
    "        elif nor_unit == 'mmol/l':\n",
    "            if exp[3] == '' and exp[2] >= 60:\n",
    "                exp[3] = 'mg'\n",
    "            if exp[3].startswith('mg'):\n",
    "                exp[2], exp[3] = exp[2]/18.0, nor_unit\n",
    "            elif exp[3].startswith('g/l'):\n",
    "                exp[2], exp[3] = exp[2]*7.745, nor_unit\n",
    "        elif nor_unit == 'kg/m2':            \n",
    "            if exp[3]!='' and exp[3] != 'kg/m2':\n",
    "                exp[3] = nor_unit\n",
    "            elif exp[3] == '':\n",
    "                exp[3] = nor_unit\n",
    "        elif nor_unit == 'mg/dl':\n",
    "            if exp[3] == '' and exp[2] >= 100:\n",
    "                exp[3] = 'mol'\n",
    "            if exp[3].startswith('umol') or exp[3].startswith('mol') or exp[3].startswith('micromol'):\n",
    "                exp[2], exp[3] = exp[2]/88.4, nor_unit\n",
    "            elif exp[3] == 'mmol/l':\n",
    "                exp[2], exp[3] = exp[2]*18.0, nor_unit\n",
    "            elif exp[3].startswith('mg/g'):\n",
    "                exp[2], exp[3] = exp[2]/1000.0, nor_unit\n",
    "        elif exp[3] == '' and nor_unit != \"\":\n",
    "            exp[3] = nor_unit\n",
    "        exp[2] = round(exp[2], 2)\n",
    "        exp_temp.append(exp)\n",
    "#         exps[i] = exp_temp\n",
    "    return exp_temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heuristic rule-based validation     \n",
    "def hr_validation(exps_temp, min_value, max_value):\n",
    "    # ------------------ judge an exp by its value comparing with average value. 100 mg/dl, 1 (day), in this case, 1 (day) will be removed\n",
    "    exps = []\n",
    "    tagg_temp = []\n",
    "    # validation by comparing with average value step1. This has been tested to be not as valid as the previous validation method\n",
    "#     total, num = 0.0, 0.0\n",
    "#     for exp in exps_temp:\n",
    "#         if exp[3] <> '':\n",
    "#            total += float(exp[2])\n",
    "#            num += 1\n",
    "           \n",
    "    thre1, thre2 = 2.0, 8.0 \n",
    "    for exp in exps_temp:\n",
    "        if exp[3].startswith('x ') or exp[3].startswith('times'):\n",
    "            tagg_temp.append(exp)\n",
    "            continue\n",
    "        # validation by heuristic rules\n",
    "        if float(exp[2]) < min_value/thre1 or float(exp[2]) > max_value*thre1: \n",
    "            continue\n",
    "\n",
    "        # validation by comparing with average value step2. This has been tested to be not as valid as the previous validation method            \n",
    "#         if exp[3] == '' and num > 0 and (total/num >= thre2*float(exp[2]) or float(exp[2]) >= thre2*total/num):\n",
    "#             continue\n",
    "        \n",
    "        tagg_temp.append(exp)\n",
    "    return tagg_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-aaa5d84b1c2b>, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-aaa5d84b1c2b>\"\u001b[1;36m, line \u001b[1;32m35\u001b[0m\n\u001b[1;33m    if exp[3]<>'' and exp[3] <> 'kg/m2':\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#====================normalize the unit and their corresponding values\n",
    "def normalization (nor_unit, exps):\n",
    "#     for i in xrange(len(exps)):\n",
    "    exp_temp = []\n",
    "    for exp in exps:\n",
    "        if ' x ' in exp[2]: \n",
    "            temp = exp[2].strip().split(' x ')\n",
    "            exp[2] = 1\n",
    "            for tem in temp:\n",
    "                exp[2] = exp[2] * float(tem)\n",
    "        elif '^' in exp[2]:\n",
    "            temp = exp[2].split('^')\n",
    "            x,y = float(temp[0].strip()),float(temp[1].strip())\n",
    "            exp[2] = math.pow(x, y)\n",
    "        else:\n",
    "            exp[2] = float(exp[2])\n",
    "        # start define unit conversion\n",
    "        if nor_unit == '%':\n",
    "            if exp[3] == '' and exp[2] < 1:\n",
    "                exp[2], exp[3] = exp[2]*100.0, nor_unit\n",
    "            elif exp[3].startswith('percent'):\n",
    "                exp[3] = nor_unit\n",
    "            elif exp[3].startswith('mmol/mol'):\n",
    "                exp[2], exp[3] = exp[2]/10.0, nor_unit\n",
    "            elif exp[3] =='':\n",
    "                exp[3] = nor_unit\n",
    "        elif nor_unit == 'mmol/l':\n",
    "            if exp[3] == '' and exp[2] >= 60:\n",
    "                exp[3] = 'mg'\n",
    "            if exp[3].startswith('mg'):\n",
    "                exp[2], exp[3] = exp[2]/18.0, nor_unit\n",
    "            elif exp[3].startswith('g/l'):\n",
    "                exp[2], exp[3] = exp[2]*7.745, nor_unit\n",
    "        elif nor_unit == 'kg/m2':            \n",
    "            if exp[3]<>'' and exp[3] <> 'kg/m2':\n",
    "                exp[3] = nor_unit\n",
    "            elif exp[3] == '':\n",
    "                exp[3] = nor_unit\n",
    "        elif nor_unit == 'mg/dl':\n",
    "            if exp[3] == '' and exp[2] >= 100:\n",
    "                exp[3] = 'mol'\n",
    "            if exp[3].startswith('umol') or exp[3].startswith('mol') or exp[3].startswith('micromol'):\n",
    "                exp[2], exp[3] = exp[2]/88.4, nor_unit\n",
    "            elif exp[3] == 'mmol/l':\n",
    "                exp[2], exp[3] = exp[2]*18.0, nor_unit\n",
    "            elif exp[3].startswith('mg/g'):\n",
    "                exp[2], exp[3] = exp[2]/1000.0, nor_unit\n",
    "        elif exp[3] == '' and nor_unit != \"\":\n",
    "            exp[3] = nor_unit\n",
    "        exp[2] = round(exp[2], 2)\n",
    "        exp_temp.append(exp)\n",
    "#         exps[i] = exp_temp\n",
    "    return exp_temp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from W_utility.log import * \n",
    "from W_utility.file import * \n",
    "\n",
    "from NLP.porter2 import *\n",
    "from NLP.word import *\n",
    "from NLP.sentence import *\n",
    "from NLP.sentence_keywords import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, math, csv\n",
    "import W_utility.file as ufile\n",
    "from NLP import sentence\n",
    "from NLP import sentence_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare vars to empty\n",
    "greater, greater_equal, greater_equal2, lower, lower_equal, lower_equal2, equal, between, selects, connect, features, temporal, temporal_con, error1, error2, symbols, numbers, unit_special, unit_ori, unit_ori_s, unit_exp, negation = \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
    "\n",
    "def init_features ():\n",
    "    # Import csv data as dictionary \n",
    "    feature_set = ufile.read_csv_as_dict ('data\\\\numeric_features.csv', 0, 1, True)\n",
    "    \n",
    "    # Declare Global variables from the imported data\n",
    "    global greater, greater_equal, greater_equal2, lower, lower_equal, lower_equal2, equal, between, selects, connect, features, temporal, temporal_con, error1, error2, symbols, numbers, unit_special, unit_ori, unit_ori_s, unit_exp, negation\n",
    "    greater, greater_equal, greater_equal2, lower, lower_equal, lower_equal2, equal, between, selects, connect, features, temporal, temporal_con, error1, error2, symbols, numbers, unit_special, unit_ori, unit_ori_s, unit_exp, negation = \\\n",
    "    feature_set[\"greater\"], feature_set[\"greater_equal\"], feature_set[\"greater_equal2\"], feature_set[\"lower\"], feature_set[\"lower_equal\"], feature_set[\"lower_equal2\"], feature_set[\"equal\"], feature_set[\"between\"], feature_set[\"selects\"], feature_set[\"connect\"], feature_set[\"features\"], feature_set[\"temporal\"], feature_set[\"temporal_con\"], feature_set[\"error1\"], feature_set[\"error2\"], feature_set[\"symbols\"], feature_set[\"numbers\"], feature_set[\"unit_special\"], feature_set[\"unit_ori\"], feature_set[\"unit_ori_s\"], feature_set[\"unit_exp\"], feature_set[\"negation\"]\n",
    "    \n",
    "    # ADD plural form of words in temporal \n",
    "    temporal = temporal + '|' + temporal.replace('|', 's|') + 's'\n",
    "    \n",
    "    # Create a new varibale that consists of words in unit_ori, unit_ori_s, plural form of words in unit_ori_s, temporal\n",
    "    unit = (unit_ori + \"|\" + unit_ori_s.replace(\"|\", \"s|\") + \"s|\" + unit_ori_s + \"|\" + temporal)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Text replace sor sub\n",
    "def preprocessing (text):\n",
    "    # handle special characters\n",
    "    text = text.encode().decode('ascii', 'ignore')\n",
    "    \n",
    "    # Strip() is used to remove whitespace here. #Strip is used to remove leading & trailing characters. If omitted or None, the chars argument defaults to removing whitespace.\n",
    "    # '#' is used the 'example data diabetes_Type 1.csv' to end a sentence. Hence \\n\\n is replaced with #\n",
    "    text = text.strip().replace('\\n\\n', '#') \n",
    "    \n",
    "    # \\n is replced with empty\n",
    "    text = text.replace ('\\n', '')\n",
    "    \n",
    "    text = text.replace(u'＝','=').replace(u'＞', '>').replace(u'＜','<').replace(u'≤','<=').replace (u'≥','>=').replace(u'≦','<=').replace(u'≧','>=').replace(u'mm³','mm^3').replace(u'µl','ul').replace(u'µL','ul').replace(u'·','').replace(u'‐','-').replace(u'—','-')\n",
    "    \n",
    "    # Double brackets are replced with single brackets\n",
    "    text = text.replace('((', '(').replace('))', ')')\n",
    "    \n",
    "    \n",
    "    # \"105&200\" converted to \"105 - 200\"\n",
    "    # \"105 & 200\" converted to \"105 - 200\"\n",
    "    # & or / or ~ is replced with -\n",
    "    # \\1 corresponds to 1st char/string i.e (\\d+) \n",
    "    # \\5 corresponds to 5th char/string i.e (\\d+)\n",
    "    # ( |) - corresponds to if space is present or not\n",
    "    text = re.sub('(\\d+)( |)(~|/|&|\\|)( |)(\\d+)',r'\\1 - \\5',text) # e.g., '10~20' to '10 ~ 20'\n",
    "    \n",
    "    # Commas in only thousands is replaced (Makes sense as if r\"(\\d+),(\\d+)\" is used instead, July24,2017 will be changed to July242017 & in 10/19,10/20 will be changed to 10/1910/20)\n",
    "    text = re.sub(r\"(\\d+),(\\d{3})\", r'\\1\\2', text) # 10,123 to 10123\n",
    "    \n",
    "    # Should be run only using DateTime function\n",
    "    # If only 1 or 2 digits are present after 'digits followed by comma' \n",
    "    # Not needed to run this \n",
    "    text = re.sub(r\"(\\d+),(\\d{1,2})\", r'\\1.\\2', text) # 10,1 to 10.1\n",
    "    \n",
    "    # r\"between (\\d+), (\\d{1,2}) (and|or) \", r'between \\1.\\2 \\3 ' MODIFIED TO  r\"between (\\d+),( |)(\\d{1,2}) (and|or) \", r'between \\1.\\3 \\4 '\n",
    "    # Not needed to run this\n",
    "    text = re.sub(r\"between (\\d+),( |)(\\d{1,2}) (and|or) \", r'between \\1.\\3 \\4 ', text) # 'between 7, 5 and ' to 'between 7.5 and '\n",
    "    \n",
    "    # Within a text if there double spaces - replace it with a single space\n",
    "    while '  ' in text:\n",
    "        text = text.replace('  ',' ')\n",
    "    \n",
    "    # Global variable - Declared in init_features (comma before but|and|or is removed )\n",
    "    # avoid connected values separated by splitting, e.g., \", but below 10%\"\n",
    "    text = re.sub(\", (\"+connect+\") \", r' \\1 ', text) # \n",
    "\n",
    "    # text is converted to lowercase\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX #\n",
    "### example data diabetes_Type 1 contains some key words exclusion, inclusion, keywords mentioned in in_fea, ex_fea\n",
    "# This can be ignored for our data (As we are not splitting our data to Inclusion, Exclusion subgroups)\n",
    "def split_text_inclusion_exclusion(otext):\n",
    "    in_fea = 'inclusion criteria:|key inclusion criteria|inclusion criteria [^:#;\\.]+:|inclusion:|(?<!(\\w| ))inclusion criteria\\W\\W|inclusion for'\n",
    "    ex_fea = 'exclusion criteria:|key exclusion criteria|exclusion criteria [^:#;\\.]+:|exclusion:|(?<!(\\w| ))exclusion criteria\\W\\W|exclusion for'\n",
    "   \n",
    "    # Declare vars to empty, to use them in for loops\n",
    "    in_text, ex_text = '', ''\n",
    "    \n",
    "    # in_bool is initially set to true but modified in While loop\n",
    "    in_bool = True\n",
    "    \n",
    "    # text is converted to lowercase\n",
    "    text = otext.lower()\n",
    "    \n",
    "    # If text is NOT empty\n",
    "    while text != '':\n",
    "        # if in_bool is True:\n",
    "        if in_bool:\n",
    "            n_pos = re.search('('+ex_fea+')',text)\n",
    "            if n_pos is not None:\n",
    "                in_text += text[0:n_pos.start()]\n",
    "                text = text[n_pos.start():]\n",
    "            else:\n",
    "                in_text += text[0:]\n",
    "                text = ''\n",
    "        \n",
    "        # if in_bool is False\n",
    "        else:\n",
    "            n_pos = re.search('('+in_fea+')',text)\n",
    "            if n_pos is not None:\n",
    "                ex_text += text[0:n_pos.start()]\n",
    "                text = text[n_pos.start():]\n",
    "            else:\n",
    "                ex_text += text[0:]\n",
    "                text = ''\n",
    "        in_bool = False if in_bool else True\n",
    "    \n",
    "    sections_text =[]\n",
    "    if in_text !='': sections_text.append([\"Inclusion\", in_text])\n",
    "    if ex_text !='': sections_text.append([\"Exclusion\", ex_text])    \n",
    "    return sections_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX #\n",
    "#====find expression candidates according to pre-defined feature list\n",
    "# This whole function can be replaced with the below one\n",
    "def extract_candidates_numeric (text):\n",
    "    # process text\n",
    "    sections_text = split_text_inclusion_exclusion(text)\n",
    "    \n",
    "    sections_num = []\n",
    "    candidates_num = []\n",
    "      \n",
    "    # Each sections i.e ['inclusion','its text']\n",
    "    for section_text in sections_text:        \n",
    "        # Within each paragraph (section_text[1]) , split sentences based on characters - [#!?.;]\\s (/s is whitespace character)\n",
    "        sentences = sentence.sentence_splitting_symbols(section_text[1], \"[#!?.;]\\s\", 1)\n",
    "        for sent in sentences:\n",
    "            #Strip is used to remove leading & trailing characters. Here '- ' is removed \n",
    "            sent = sent.strip().strip('- ')\n",
    "            if sent == '':\n",
    "                continue\n",
    "                \n",
    "            digit = re.search(\"(?<!(\\w))\\d+\", sent)\n",
    "            if digit:\n",
    "                sections_num.append(section_text[0])\n",
    "                candidates_num.append(sent)\n",
    "\n",
    "    return (sections_num, candidates_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find sentences that have numeric values in them. (splits paragraph into sentences and extracts only those with numerics in them)\n",
    "def extract_candidates_numeric (text):\n",
    "    \n",
    "    # Split text into sentences\n",
    "    sentences = sentence.sentence_splitting_symbols(text, \"[#!?.;]\\s\", 1)\n",
    "    # Create a empty array\n",
    "    candidates_num = []\n",
    "    \n",
    "    for sent in sentences:\n",
    "        #Strip is used to remove leading & trailing characters. Here '- ' is removed \n",
    "        sent = sent.strip().strip('- ')\n",
    "        \n",
    "        if sent == '':\n",
    "            continue\n",
    "\n",
    "        digit = re.search(\"(?<!(\\w))\\d+\", sent) # Searching for a digit\n",
    "        if digit:\n",
    "            candidates_num.append(sent) # Append sentences that have numeric values, to the array\n",
    "            \n",
    "    return (candidates_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX #\n",
    "# Extract only sentences with a particular name/string/word. If name_list is empty then there is NO restriction on which sentences to extract\n",
    "# Function modified to meet extract_candidates_numeric new function\n",
    "name_list = \"\"\n",
    "def extract_candidates_name (candidates_num, name_list):\n",
    "    \n",
    "    candidates = []\n",
    "    \n",
    "    # If name_list=\"heart rate | temperature | blood pressure\"; name_list.split('|') splits to give ['heart rate ', ' temperature ', ' blood pressure']\n",
    "    names = name_list.split('|') \n",
    "    for i in range(len(candidates_num)):            \n",
    "        for name in names:\n",
    "           if name in candidates_num[i]: #If string/word is in the sentence it is appended\n",
    "                candidates.append(candidates_num[i]) # Append \n",
    "                break\n",
    "            \n",
    "            # else statement is NOT present as if name_list is empty all sentences are extracted\n",
    "\n",
    "    return (candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====identify expressions and formalize them into labels \"<VML(tag) L(logic, e.g., greater_equal)=X U(unit)=X>value</VML>\"\n",
    "def formalize_expressions (candidate):\n",
    "    text = candidate\n",
    "    csvfile = open('data\\\\rules.csv', 'r')\n",
    "    reader = csv.reader(csvfile)\n",
    "    now_pattern = \"preprocessing\"\n",
    "\n",
    "    for i,pattern in enumerate(reader):\n",
    "        source_pattern = pattern[0]\n",
    "        target_pattern = pattern[1]\n",
    "        pattern_function = pattern[2]\n",
    "\n",
    "        if(pattern_function == \"process_numerical_values\" and pattern_function != now_pattern):\n",
    "            matchs = re.findall('<Unit>([^<>]+)</Unit>', text)\n",
    "            for match in matchs: text = text.replace(match, match.replace(' / ', '/').replace(' - ','-'))\n",
    "\n",
    "        if(pattern_function == \"process_special_logics\" and pattern_function != now_pattern):\n",
    "            # process 'select' expression, use the first one\n",
    "            selects = \"X \\( X \\)|X \\( equal to X \\)|X \\( = X\\)\"\n",
    "            aselect = selects.split('|')\n",
    "            for selec in aselect:\n",
    "                selec = selec.replace('X', '<VML Unit([^<>]+)>([^<>]+)</VML>')\n",
    "                text = re.sub(selec, r'<VML Unit\\1>\\2</VML>', text) #\n",
    "\n",
    "            #  process 'between' expressions\n",
    "            between = \"range of X to X|range X to X|range X - X|between X to X|between X and X|between Xand X|between X - X|between X & X|from X to X|within X to X|start X and X|X through X|of X and X|>= X and X|> X and X|of X to X|>= X to <= X|>= X to X|> X to X|X - <= X|X to X|X - X\"\n",
    "            betweens = between.split('|')\n",
    "            for betw in betweens:\n",
    "                betw = betw.replace('X', '<VML Unit([^<>]+)>([^<>]+)</VML>')\n",
    "                text = re.sub(betw, r'<VML Logic=greater_equal Unit\\1>\\2</VML> - <VML Logic=lower_equal Unit\\3>\\4</VML>', text) #\n",
    "        text = re.sub(source_pattern, target_pattern, text)\n",
    "        now_pattern = pattern_function\n",
    "\n",
    "    csvfile.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ExampleData = pd.read_csv(\"data/example data diabetes_Type 1.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',-1)\n",
    "ExampleData"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
